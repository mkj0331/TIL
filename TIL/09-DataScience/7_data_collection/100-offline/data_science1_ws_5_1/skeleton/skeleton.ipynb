{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fee4774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eafe7f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSL 경고 비활성화\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7c2725d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문제 1. 웹페이지 가져오기\n",
      "답: 상태 코드: 200\n",
      "설명: 상태 코드 200은 웹페이지가 성공적으로 로드되었음을 의미합니다.\n"
     ]
    }
   ],
   "source": [
    "# 1. 웹페이지 가져오기\n",
    "url = \"https://topis.seoul.go.kr/\"\n",
    "response = requests.get(url, verify=False)  # SSL 인증서 검증 비활성화 후 가져오기\n",
    "print(\"문제 1. 웹페이지 가져오기\")\n",
    "print(\"답: 상태 코드:\", response.status_code)  # 응답의 상태 코드를 출력합니다.\n",
    "print(\"설명: 상태 코드 200은 웹페이지가 성공적으로 로드되었음을 의미합니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c8be9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "문제 2. <title> 태그 내용 추출\n",
      "답: 웹페이지 제목: 서울시 교통정보 시스템 - TOPIS**\n",
      "설명: BeautifulSoup을 사용하여 HTML에서 <title> 태그의 내용을 추출했습니다.\n"
     ]
    }
   ],
   "source": [
    "# 2. <title> 태그 내용 추출\n",
    "soup = BeautifulSoup(response.text, 'html.parser')  # HTML 파서를 지정합니다.\n",
    "title = soup.find('title')  # <title> 태그를 찾습니다.\n",
    "print(\"\\n문제 2. <title> 태그 내용 추출\")\n",
    "print(\"답: 웹페이지 제목:\", title.text if title else \"제목 없음\")  # title의 텍스트를 출력합니다.\n",
    "print(\"설명: BeautifulSoup을 사용하여 HTML에서 <title> 태그의 내용을 추출했습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "111a21b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "문제 3. <a> 태그 개수 세기\n",
      "답: 링크 개수: 78\n",
      "설명: find_all() 메소드를 사용하여 모든 <a> 태그를 찾고, 그 개수를 계산했습니다.\n"
     ]
    }
   ],
   "source": [
    "# 3. <a> 태그 개수 세기\n",
    "links = soup.find_all('a')  # 모든 <a> 태그를 찾습니다.\n",
    "print(\"\\n문제 3. <a> 태그 개수 세기\")\n",
    "print(\"답: 링크 개수:\", len(links))  # links의 길이를 출력합니다.\n",
    "print(\"설명: find_all() 메소드를 사용하여 모든 <a> 태그를 찾고, 그 개수를 계산했습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95a543d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "문제 4. 외부 링크 필터링 후 첫 5개의 href 속성 출력\n",
      "답: ['https://news.seoul.go.kr/traffic/greentraffic', 'http://175.193.202.152/simulator/login', 'https://bus.go.kr/app/#viewpage/1000003/main.subwayinfo/1/title=Home%20%3E%20%EC%A7%80%ED%95%98%EC%B2%A0%EC%A0%95%EB%B3%B4', 'http://blog.naver.com/haechiseoul/223417334954', 'https://news.seoul.go.kr/traffic/greentraffic']\n",
      "설명: href 속성에 'http' 또는 'https'가 포함된 외부 링크를 필터링하여 출력했습니다.\n"
     ]
    }
   ],
   "source": [
    "# 4. 외부 링크 필터링 후 첫 5개의 href 속성 출력\n",
    "external_links = [link.get('href') for link in links if link.get('href') and ('http' in link.get('href') or 'https' in link.get('href'))]  # 외부 링크만 필터링합니다.\n",
    "print(\"\\n문제 4. 외부 링크 필터링 후 첫 5개의 href 속성 출력\")\n",
    "print(\"답:\", external_links[0:5])  # 첫 5개의 외부 링크를 출력합니다.\n",
    "print(\"설명: href 속성에 'http' 또는 'https'가 포함된 외부 링크를 필터링하여 출력했습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1428ae21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "문제 5. 'traffic' 또는 '교통'이 포함된 텍스트 찾기\n",
      "답: 'traffic' 또는 '교통'이 포함된 텍스트:\n",
      "  - 서울시 교통정보 열람\n",
      "  - 교통량 정보\n",
      "  - 대중교통 정보\n",
      "  - 교통이용 통계\n",
      "  - 교통 현황\n",
      "  - 녹색교통지역 안내\n",
      "  - <div><a href=\"https://topis.seoul.go.kr/notice/openCardNews.do\" target=\"_blank\"><img src=\"/images/banner/seoulTraffic.jpg\" alt=\"서울교통 주간 브리핑\"></a></div>\n",
      "  - <div><a href=\"https://play.google.com/store/apps/details?id=kr.go.seoul.mydata\" target=\"_blank\"><img src=\"/images/banner/My-T.jpg\" alt=\"대중교통 코로나 안심앱\"></a></div>\n",
      "  - 트위터 실시간 교통정보\n",
      "  - 교통량정보\n",
      "  - 교통량정보 시작//\n",
      "  - 교통량정보 끝//\n",
      "  - 서울시의 다양한 교통정보를 open API로 제공합니다.\n",
      "  - 대중교통 O/D 현황\n",
      "  - 교통예보\n",
      "  - ※ 3일전 교통카드 데이터를 기반으로 한 자료입니다.\n",
      "  - 지하철 교통현황\n",
      "  - 버스 교통현황\n",
      "  - 지하철 교통현황\n",
      "  - 버스 교통현황\n",
      "  - 서울시 교통정보 열람\n",
      "  - Dighty : [서울시 교통정보 시스템] 하단 (300*100) 태그\n",
      "설명: 'traffic' 또는 '교통'이라는 단어가 포함된 텍스트를 찾고, 지정된 태그에서만 추출하여 출력했습니다.\n"
     ]
    }
   ],
   "source": [
    "# 5. 'traffic' 또는 '교통'이 포함된 텍스트 찾기\n",
    "traffic_texts = soup.find_all(string=lambda string: any(keyword in string.lower() for keyword in ['traffic', '교통']) if string else False)  # 'traffic' 또는 '교통'이 포함된 텍스트 찾기\n",
    "filtered_texts = [text.strip() for text in traffic_texts if text.parent.name in ['p', 'div', 'span', 'li', 'strong', 'a']]  # 특정 태그 내에서 텍스트 추출\n",
    "print(\"\\n문제 5. 'traffic' 또는 '교통'이 포함된 텍스트 찾기\")\n",
    "print(\"답: 'traffic' 또는 '교통'이 포함된 텍스트:\")\n",
    "for text in filtered_texts:\n",
    "    print(\"  -\", text)  # 각 텍스트를 출력합니다.\n",
    "print(\"설명: 'traffic' 또는 '교통'이라는 단어가 포함된 텍스트를 찾고, 지정된 태그에서만 추출하여 출력했습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c004c20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
